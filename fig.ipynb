{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from scripts.utils.utils import summarize_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"liar\"\n",
    "totals = {}\n",
    "for load in [\"ig\", \"lime\", \"shap\"]:\n",
    "    with torch.no_grad():\n",
    "        models = {}\n",
    "        for item in os.listdir(f\"./pt/{ds}/{load}/\"):\n",
    "            models[item] = []\n",
    "            for idx, pt in enumerate(os.listdir(f\"./pt/{ds}/{load}/{item}\")):\n",
    "                pt: torch.Tensor = torch.load(f\"./pt/{ds}/{load}/{item}/{pt}\")[0]\n",
    "                if load != \"ig\":\n",
    "                    models[item].append(pt.detach())\n",
    "                else:\n",
    "                    models[item].append(summarize_attributions(pt.detach()))\n",
    "    totals[load] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ig', 'lime', 'shap'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Llama-2-7b-chat-hf', 'Orca-2-7b', 'falcon-7b-instruct', 'Mistral-7B-Instruct-v0.2'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals['ig'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in totals['ig'].keys():\n",
    "#     assert len(totals['ig'][model]) == len(totals['lime'][model])\n",
    "#     assert len(totals['ig'][model]) == len(totals['shap'][model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ig', 'lime', 'shap'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = {}\n",
    "for exp in totals:\n",
    "    cats[exp]  = torch.cat([torch.cat(totals[exp][model]) for model in totals[exp]])\n",
    "cats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs means:  ig: 0.026, lime: 0.008, shap: 0.030\n",
      "std:  ig: 0.048, lime: 0.018, shap: 0.043\n"
     ]
    }
   ],
   "source": [
    "print(f\"abs means:  ig: {cats['ig'].abs().mean():.3f}, lime: {cats['lime'].abs().mean():.3f}, shap: {cats['shap'].abs().mean():.3f}\")\n",
    "print(f\"std:  ig: {cats['ig'].std():.3f}, lime: {cats['lime'].std():.3f}, shap: {cats['shap'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs means:  ig: 0.026, lime: 0.007, shap: 0.029\n",
      "std:  ig: 0.042, lime: 0.015, shap: 0.039\n"
     ]
    }
   ],
   "source": [
    "# try calculating (mean, std) per-sample before averaging them\n",
    "per_sample_means = {}\n",
    "per_sample_std = {}\n",
    "for exp in totals:\n",
    "    per_sample_means[exp] = torch.tensor([torch.tensor([el.abs().mean() for el in totals[exp][model]]).mean() for model in totals[exp]]).mean()\n",
    "    per_sample_std[exp] = torch.tensor([torch.tensor([el.std() for el in totals[exp][model]]).mean() for model in totals[exp]]).mean()\n",
    "print(f\"abs means:  ig: {per_sample_means['ig']:.3f}, lime: {per_sample_means['lime']:.3f}, shap: {per_sample_means['shap']:.3f}\")\n",
    "print(f\"std:  ig: {per_sample_std['ig']:.3f}, lime: {per_sample_std['lime']:.3f}, shap: {per_sample_std['shap']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average number of tokens that together add up to the absolute value of the sample\n",
    "# basically, how many tokens on average it takes to mostly represent a sample\n",
    "def num_representative(t: torch.Tensor, thresh:float=0.8)->int:\n",
    "    t= t.abs()\n",
    "    s = t.sum()\n",
    "\n",
    "    max_sorted = t.sort(descending=True)\n",
    "    cur_sum = 0\n",
    "    n = 0\n",
    "    while cur_sum < thresh * s:\n",
    "        cur_sum += max_sorted.values[n]\n",
    "        n += 1\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_representative(torch.tensor([0.9, 0.8, 0.1, -0.5, -11.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg percentage of tokens needed to make up 85% of a sample's magnitude:  ig: 0.476, lime: 0.403, shap: 0.560\n"
     ]
    }
   ],
   "source": [
    "avg_num_representative_percent = {}\n",
    "for exp in totals:\n",
    "    avg_num_representative_percent[exp] = torch.cat([torch.tensor([num_representative(sample, 0.85) / sample.shape[0] for sample in totals[exp][model]], dtype=torch.float) for model in totals[exp]]).mean()\n",
    "print(f\"avg percentage of tokens needed to make up 85% of a sample's magnitude:  ig: {avg_num_representative_percent['ig']:.3f}, lime: {avg_num_representative_percent['lime']:.3f}, shap: {avg_num_representative_percent['shap']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg number of tokens needed to make up 85% of a sample's magnitude:  ig: 41.042, lime: 35.220, shap: 48.423\n"
     ]
    }
   ],
   "source": [
    "avg_num_representative = {}\n",
    "for exp in totals:\n",
    "    avg_num_representative[exp] = torch.cat([torch.tensor([num_representative(sample, 0.85) for sample in totals[exp][model]], dtype=torch.float) for model in totals[exp]]).mean()\n",
    "print(f\"avg number of tokens needed to make up 85% of a sample's magnitude:  ig: {avg_num_representative['ig']:.3f}, lime: {avg_num_representative['lime']:.3f}, shap: {avg_num_representative['shap']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ig': tensor(41.0425), 'lime': tensor(35.2200), 'shap': tensor(48.4231)}\n",
      "{'Llama-2-7b-chat-hf': tensor(42.1250), 'Orca-2-7b': tensor(42.4780), 'falcon-7b-instruct': tensor(36.8300), 'Mistral-7B-Instruct-v0.2': tensor(43.7600)}\n",
      "\n",
      "Experiment Type & Llama-2-7b-chat-hf & Orca-2-7b & falcon-7b-instruct & Mistral-7B-Instruct-v0.2 & Average\n",
      "ig & 40.130 & 41.230 & 38.680 & 44.130 &  41.042\n",
      "lime & 38.960 & 41.200 & 23.820 & 36.900 &  35.220\n",
      "shap & 49.280 & 48.375 & 46.140 & 49.880 &  48.423\n",
      "Average & 42.125 & 42.478 & 36.830 & 43.760 & \n"
     ]
    }
   ],
   "source": [
    "average_tokens = {}\n",
    "for exp in totals:\n",
    "    average_tokens[exp] = {model: torch.tensor([num_representative(sample, 0.85) for sample in totals[exp][model]], dtype=torch.float) for model in totals[exp]}\n",
    "\n",
    "# sum rows:\n",
    "summed_rows = {exp: torch.cat([val for val in average_tokens[exp].values()]).mean() for exp in average_tokens}\n",
    "print(summed_rows)\n",
    "# sum cols\n",
    "summed_cols = {model: torch.cat([average_tokens[exp][model] for exp in totals]).mean() for model in average_tokens['ig']}\n",
    "print(summed_cols)\n",
    "\n",
    "print()\n",
    "# models on top\n",
    "# types on left\n",
    "# so each row will print out the models' results for that type, as well as the total result for that type\n",
    "\n",
    "result_str = \"Experiment Type\"\n",
    "for model in average_tokens['ig']:\n",
    "    result_str += f\" & {model}\"\n",
    "result_str += \" & Average\\n\"\n",
    "for exp in totals:\n",
    "    result_str += f\"{exp} & \"\n",
    "    for model in average_tokens[exp]:\n",
    "        result_str += f\"{average_tokens[exp][model].mean():.3f} & \"\n",
    "    result_str += f\" {summed_rows[exp]:.3f}\\n\"\n",
    "\n",
    "result_str += \"Average & \"\n",
    "for model in average_tokens['ig']:\n",
    "    result_str += f\"{summed_cols[model]:.3f} & \"\n",
    "\n",
    "print(result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ig': tensor(0.4758), 'lime': tensor(0.4034), 'shap': tensor(0.5605)}\n",
      "{'Llama-2-7b-chat-hf': tensor(0.4754), 'Orca-2-7b': tensor(0.4802), 'falcon-7b-instruct': tensor(0.4472), 'Mistral-7B-Instruct-v0.2': tensor(0.5055)}\n",
      "\n",
      "Experiment Type & Llama-2-7b-chat-hf & Orca-2-7b & falcon-7b-instruct & Mistral-7B-Instruct-v0.2 & Average\n",
      "ig & 45.5\\% & 46.6\\% & 47.0\\% & 51.2\\% &  47.6\\%\n",
      "lime & 43.8\\% & 46.2\\% & 29.0\\% & 42.4\\% &  40.3\\%\n",
      "shap & 55.4\\% & 55.1\\% & 55.9\\% & 57.5\\% &  56.0\\%\n",
      "Average & 47.5\\% & 48.0\\% & 44.7\\% & 50.5\\% & \n"
     ]
    }
   ],
   "source": [
    "average_tokens = {}\n",
    "for exp in totals:\n",
    "    average_tokens[exp] = {model: torch.tensor([num_representative(sample, 0.85) / sample.shape[0] for sample in totals[exp][model]], dtype=torch.float) for model in totals[exp]}\n",
    "\n",
    "# sum rows:\n",
    "summed_rows = {exp: torch.cat([val for val in average_tokens[exp].values()]).mean() for exp in average_tokens}\n",
    "print(summed_rows)\n",
    "# sum cols\n",
    "summed_cols = {model: torch.cat([average_tokens[exp][model] for exp in totals]).mean() for model in average_tokens['ig']}\n",
    "print(summed_cols)\n",
    "\n",
    "print()\n",
    "# models on top\n",
    "# types on left\n",
    "# so each row will print out the models' results for that type, as well as the total result for that type\n",
    "\n",
    "result_str = \"Experiment Type\"\n",
    "for model in average_tokens['ig']:\n",
    "    result_str += f\" & {model}\"\n",
    "result_str += \" & Average\\n\"\n",
    "for exp in totals:\n",
    "    result_str += f\"{exp} & \"\n",
    "    for model in average_tokens[exp]:\n",
    "        result_str += f\"{average_tokens[exp][model].mean()*100:.1f}\\\\% & \"\n",
    "    result_str += f\" {summed_rows[exp]*100:.1f}\\\\%\\n\"\n",
    "\n",
    "result_str += \"Average & \"\n",
    "for model in average_tokens['ig']:\n",
    "    result_str += f\"{summed_cols[model]*100:.1f}\\\\% & \"\n",
    "\n",
    "print(result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
