{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5186fc96da1e4352b91624da6b7fdb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"posicube/Llama2-chat-AYT-13B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.txt\", \"w\") as file:\n",
    "    file.write(str(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"it has been said that cheese is good for the body\", \"hi there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 372, 756, 1063, 1497, 393, 923, 968, 338, 1781, 363, 278, 3573]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamaOutputs = tokenizer(inputs, padding=\"longest\")\n",
    "llamaOutputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we know how to use tokenizers\n",
    "# we can use faiss to compare tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertTokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522321"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"bertVocab.txt\", \"w\").write(str(bertTokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2009, 2038, 2042, 2056, 2008, 8808, 2003, 2204, 2005, 1996, 2303, 102]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertOutputs = bertTokenizer(inputs, padding=\"longest\")\n",
    "bertOutputs[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bertOutputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llamaOutputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(np.array([bertOutputs['input_ids'][0], llamaOutputs['input_ids'][0]], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "bertModel = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertModel.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertEmbeddings = bertModel.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertEmbeddings.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedInput = bertTokenizer(\"hi there, I would like to order a [MASK] please\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in encodedInput:\n",
    "    encodedInput[item].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7632, 2045, 1010, 1045, 2052, 2066, 2000, 2344, 1037,  103, 3531,\n",
       "          102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -6.8868,  -6.8263,  -6.8384,  ...,  -6.1582,  -6.0658,  -4.1332],\n",
       "         [ -9.0659,  -9.1499,  -9.4144,  ...,  -8.8747,  -8.6684,  -7.9443],\n",
       "         [ -8.8072,  -8.6691,  -9.0157,  ...,  -6.5108,  -9.4665,  -7.6807],\n",
       "         ...,\n",
       "         [ -6.2883,  -6.2995,  -6.2399,  ...,  -5.8153,  -5.8282,  -7.1735],\n",
       "         [ -9.1955,  -8.7199,  -9.0054,  ...,  -8.0317,  -9.5727,  -4.0663],\n",
       "         [-12.7245, -12.4730, -12.4347,  ..., -10.1119, -11.0987,  -9.5461]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = bertModel(**encodedInput)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"fill-mask\", model=bertModel, tokenizer=bertTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.45235180854797363,\n",
       "  'token': 10733,\n",
       "  'token_str': 'pizza',\n",
       "  'sequence': 'hi there, i would like to order a pizza please'},\n",
       " {'score': 0.08983268588781357,\n",
       "  'token': 4157,\n",
       "  'token_str': 'coffee',\n",
       "  'sequence': 'hi there, i would like to order a coffee please'},\n",
       " {'score': 0.08926834911108017,\n",
       "  'token': 4392,\n",
       "  'token_str': 'drink',\n",
       "  'sequence': 'hi there, i would like to order a drink please'},\n",
       " {'score': 0.04524002969264984,\n",
       "  'token': 5404,\n",
       "  'token_str': 'beer',\n",
       "  'sequence': 'hi there, i would like to order a beer please'},\n",
       " {'score': 0.028834141790866852,\n",
       "  'token': 11642,\n",
       "  'token_str': 'sandwich',\n",
       "  'sequence': 'hi there, i would like to order a sandwich please'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"hi there, I would like to order a [MASK] please\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 since that's the index of 103 (the [MASK] token)\n",
    "temp = torch.softmax(output.logits[0, 10], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest prob occurs at tensor(10733) and is tensor(0.4524, grad_fn=<SelectBackward0>)\n",
      "this is the word pizza\n"
     ]
    }
   ],
   "source": [
    "highest_prob = torch.argmax(temp)\n",
    "print(\"highest prob occurs at\", highest_prob, \"and is\", temp[highest_prob])\n",
    "print(\"this is the word\", bertTokenizer.decode(highest_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually Using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method forward in module torch.nn.modules.sparse:\n",
      "\n",
      "forward(input: torch.Tensor) -> torch.Tensor method of torch.nn.modules.sparse.Embedding instance\n",
      "    Defines the computation performed at every call.\n",
      "    \n",
      "    Should be overridden by all subclasses.\n",
      "    \n",
      "    .. note::\n",
      "        Although the recipe for forward pass needs to be defined within\n",
      "        this function, one should call the :class:`Module` instance afterwards\n",
      "        instead of this since the former takes care of running the\n",
      "        registered hooks while the latter silently ignores them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bertEmbeddings.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertEmbeddingsOutput = bertEmbeddings(encodedInput['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
       "         [-0.0138, -0.0868,  0.0433,  ..., -0.0652, -0.1024, -0.0509],\n",
       "         [-0.0749,  0.0071, -0.0074,  ...,  0.0114,  0.0323,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0037, -0.0069,  0.0087,  ...,  0.0054, -0.0043, -0.0004],\n",
       "         [-0.0479, -0.0136, -0.0444,  ...,  0.0245, -0.0535, -0.0050],\n",
       "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertEmbeddingsOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertEmbeddingsOutput.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=2,learning_rate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "npBertEmbeddings = bertEmbeddingsOutput.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npBertEmbeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "npBertEmbeddings = npBertEmbeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_features = tsne.fit_transform(npBertEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliot/miniconda3/envs/torch/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/eliot/miniconda3/envs/torch/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=tsne_features[:,0], y=tsne_features[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLama thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c451cacf334239a37d8bf11d0c82a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"converted-llama\", fp16=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"converted-llama\", load_in_4bit=True, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\", \"mask_token\":\"[MASK]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 29871,    13,  8439, 29915, 29879,   263, 11148,  3304,   297,\n",
       "           590, 16423, 29871,   243,   162,   155,   180,  1724,   881,   306,\n",
       "           437, 29973,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer(\"\"\"\n",
    "There's a llama in my garden ðŸ˜± What should I do?\n",
    "\"\"\", return_tensors=\"pt\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(encoded.input_ids, max_length=encoded.input_ids.shape[-1] + 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 29871,    13,  8439, 29915, 29879,   263, 11148,  3304,   297,\n",
       "           590, 16423, 29871,   243,   162,   155,   180,  1724,   881,   306,\n",
       "           437, 29973,    13, 30003, 29992, 29933,  5371, 29934, 29946,    13,\n",
       "         29902, 29915, 29885,   451,  1854,   825,   304,   437, 29889,   306,\n",
       "         29915,   345,  2360,   750,   263, 11148,  3304,   297,   590, 16423,\n",
       "          1434, 29889,    13, 30003, 29992, 29933,  5371, 29934, 29946,    13,\n",
       "         29902, 29915, 29885,   451,  1854,   825,   304,   437, 29889,   306,\n",
       "         29915,   345,  2360]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> \\nThere's a llama in my garden ðŸ˜± What should I do?\\nâ€”@BBCR4\\nI'm not sure what to do. I've never had a llama in my garden before.\\nâ€”@BBCR4\\nI'm not sure what to do. I've never\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
