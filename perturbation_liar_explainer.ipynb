{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime And Shap Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/016854656/miniconda3/envs/torch/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'],\n",
       "    num_rows: 12836\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "liar = datasets.load_dataset(\"liar\")\n",
    "full_liar = datasets.concatenate_datasets(\n",
    "    [liar[\"train\"], liar[\"test\"], liar[\"validation\"]]\n",
    ")\n",
    "full_liar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "import captum.attr as attr\n",
    "from captum.attr import visualization as viz\n",
    "from captum._utils.models.linear_model import SkLearnLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon = \"tiiuae/falcon-7b-instruct\"\n",
    "llama = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "mistral = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "orca = \"microsoft/Orca-2-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/016854656/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/016854656/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/016854656/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ad8279d5f14069b798edf7a4ffe0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, quantization_config=config, # device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "LABEL_MAP = {\n",
    "    0: \"E\",  # 0 : False\n",
    "    1: \"C\",  # 1 : Half True\n",
    "    2: \"B\",  # 2 : Mostly True\n",
    "    3: \"A\",  # 3 : True\n",
    "    4: \"D\",  # 4 : Barely True\n",
    "    5: \"F\",  # 5 : Pants on Fire\n",
    "}\n",
    "\n",
    "\n",
    "def was_correct(decoded: str, entry: Dict[str, int]) -> bool:\n",
    "    return LABEL_MAP[entry[\"label\"]] in decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "random.seed(1770)\n",
    "entries = random.choices(list(range(len(full_liar))), k=n_examples)\n",
    "\n",
    "\n",
    "def to_zero_shot_prompt(entry: Dict[str, str]) -> str:\n",
    "    speaker = entry[\"speaker\"].replace(\"-\", \" \").title()\n",
    "    statement = entry[\"statement\"].lstrip(\"Says \")\n",
    "\n",
    "    prompt = f\"\"\"Please select the option that most closely describes the following claim by {speaker}:\\n{statement}\\n\\nA) True\\nB) Mostly True\\nC) Half True\\nD) Barely True\\nE) False\\nF) Pants on Fire (absurd lie)\\n\\nChoice: (\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def to_n_shot_prompt(n: int, entry: Dict[str, str]) -> str:\n",
    "    examples = \"\"\n",
    "    for i in range(n):\n",
    "        examples += (\n",
    "            to_zero_shot_prompt(full_liar[entries[i]])\n",
    "            + LABEL_MAP[full_liar[entries[i]][\"label\"]]\n",
    "            + \"\\n\\n\"\n",
    "        )\n",
    "    prompt = to_zero_shot_prompt(entry)\n",
    "    return examples + prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Please select the option that most closely describes the following claim by Jorge Elorza:\n",
      "The reality is that we have roughly 15,000 undocumented immigrants living in the state...\n",
      "\n",
      "A) True\n",
      "B) Mostly True\n",
      "C) Half True\n",
      "D) Barely True\n",
      "E) False\n",
      "F) Pants on Fire (absurd lie)\n",
      "\n",
      "Choice: (A) True\n",
      "\n",
      "Explanation: Jorge Elorza's statement is based on a report from the Rhode Island Department of Health, which estimated that there were approximately 15,000 undocumented immigrants living in the state in 2013. This estimate was derived from data on the number of uninsured residents, assuming a certain percentage were undocumented. While there may be some margin of error in this estimate, it is generally accepted as a reliable approximation of the number of undocumented immigrants in Rhode Island. Therefore, Jorge Elorza's statement is true.</s>\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "k = random.randint(0, len(full_liar))\n",
    "generation = tokenizer.batch_decode(\n",
    "        model.generate(\n",
    "            tokenizer(\n",
    "                to_zero_shot_prompt(full_liar[k]), return_tensors=\"pt\"\n",
    "            ).input_ids.cuda(),\n",
    "            max_new_tokens=200,\n",
    "        )\n",
    "    )[0]\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Please select the option that most closely describes the following claim by Jorge Elorza:\n",
      "The reality is that we have roughly 15,000 undocumented immigrants living in the state...\n",
      "\n",
      "A) True\n",
      "B) Mostly True\n",
      "C) Half True\n",
      "D) Barely True\n",
      "E) False\n",
      "F) Pants on Fire (absurd lie)\n",
      "\n",
      "Choice: (A) True\n",
      "\n",
      "Explanation: Jorge Elorza's statement is based on a report from the Rhode Island Department of Health, which estimated that there were approximately 15,000 undocumented immigrants living in the state in 2013. This estimate was derived from data on the number of uninsured residents, assuming a certain percentage were undocumented. While there may be some margin of error in this estimate, it is generally accepted as a reliable approximation of the number of undocumented immigrants in Rhode Island. Therefore, Jorge Elorza's statement is true.</s> \n",
      "\n",
      "Explain your answer:\n",
      "\n",
      "Jorge Elorza's statement that \"we have roughly 15,000 undocumented immigrants living in the state\" is based on a report from the Rhode Island Department of Health. The report estimated the number of undocumented immigrants in the state based on data on the number of uninsured residents, assuming a certain percentage were undocumented. This estimate is generally accepted as a reliable approximation of the number of undocumented immigrants in Rhode Island. Therefore, Jorge Elorza's statement is true.</s>\n"
     ]
    }
   ],
   "source": [
    "continuation = f\"\"\"{generation.lstrip('<s> ')}\n",
    "\n",
    "Explain your answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    tokenizer.batch_decode(\n",
    "        model.generate(\n",
    "            tokenizer(\n",
    "                continuation, return_tensors=\"pt\"\n",
    "            ).input_ids.cuda(),\n",
    "            max_new_tokens=200,\n",
    "        )\n",
    "    )[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [28741],\n",
       " 'B': [28760],\n",
       " 'C': [28743],\n",
       " 'D': [28757],\n",
       " 'E': [28749],\n",
       " 'F': [28765]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "label_tokens = {\n",
    "    \"A\": [],\n",
    "    \"B\": [],\n",
    "    \"C\": [],\n",
    "    \"D\": [],\n",
    "    \"E\": [],\n",
    "    \"F\": [],\n",
    "}\n",
    "for char, idx in vocab.items():\n",
    "    if char in label_tokens:\n",
    "        label_tokens[char].append(idx)\n",
    "label_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 28741, 'B': 28760, 'C': 28743, 'D': 28757, 'E': 28749, 'F': 28765}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tokens = {char: idxs[0] for char, idxs in label_tokens.items()}\n",
    "label_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = to_n_shot_prompt(n_examples, full_liar[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 85])\n"
     ]
    }
   ],
   "source": [
    "# get tokens for later\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  5919,  5339,   272,  3551,   369,  1080, 11640, 13966,   272,\n",
       "          2296,  3452,   486, 26955,  1744,   271,  2166, 28747,    13,  1014,\n",
       "          6940,   349,   369,   478,   506, 15756, 28705, 28740, 28782, 28725,\n",
       "         28734, 28734, 28734,   640,  2048,   286, 22475,  3687,   297,   272,\n",
       "          1665,  1101,    13,    13, 28741, 28731,  6110,    13, 28760, 28731,\n",
       "          4822,   346,  6110,    13, 28743, 28731, 18994,  6110,    13, 28757,\n",
       "         28731,   365,  6672,  6110,    13, 28749, 28731,  8250,    13, 28765,\n",
       "         28731,   367,  1549,   356,  8643,   325,  4737, 12725,  4852, 28731,\n",
       "            13,    13, 28456, 28747,   325]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME / SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIME = \"LIME\"\n",
    "SHAP = \"SHAP\"\n",
    "EXPERIMENT_TYPE = LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_results(tokens: torch.Tensor):\n",
    "    with torch.no_grad():\n",
    "        if tokenizer.bos_token_id is not None:  # falcon's is None\n",
    "            tokens[0, 0] = tokenizer.bos_token_id\n",
    "        result = model(\n",
    "            torch.where(tokens != 0, tokens, tokenizer.eos_token_id).cuda(),\n",
    "            attention_mask=torch.where(tokens != 0, 1, 0).cuda()\n",
    "        ).logits\n",
    "        ret = torch.nn.functional.softmax(result[:, -1], dim=-1).cpu()\n",
    "        assert not ret.isnan().any()\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_embeds(tokens: torch.Tensor):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(model, \"model\"):\n",
    "            return model.model.embed_tokens(tokens.cuda())\n",
    "        elif hasattr(model, \"transformer\"):\n",
    "            return model.transformer.word_embeddings(tokens.cuda())\n",
    "        raise Exception(\"Unknown model format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode text indices into latent representations & calculate cosine similarity\n",
    "def exp_embedding_cosine_distance(original_inp, perturbed_inp, _, **kwargs):\n",
    "    original_emb = get_embeds(original_inp)\n",
    "    perturbed_emb = get_embeds(perturbed_inp)\n",
    "    distance = 1 - F.cosine_similarity(original_emb, perturbed_emb, dim=-1)\n",
    "    distance[distance.isnan()] = 0\n",
    "    ret = torch.exp(-1 * (distance**2) / 2).sum()\n",
    "    assert not ret.isnan().any()\n",
    "    return ret\n",
    "\n",
    "\n",
    "# binary vector where each word is selected independently and uniformly at random\n",
    "i = 0\n",
    "\n",
    "\n",
    "def bernoulli_perturb(text, **kwargs):\n",
    "    global i\n",
    "    probs = torch.ones_like(text) * 0.5\n",
    "    probs[0, 0] = 0  # don't get rid of the start token\n",
    "    ret = torch.bernoulli(probs).long()\n",
    "    i += 1\n",
    "    return ret\n",
    "\n",
    "\n",
    "# remove absent tokens based on the intepretable representation sample\n",
    "def interp_to_input(interp_sample, original_input, **kwargs):\n",
    "    ret = original_input.clone()\n",
    "    ret[interp_sample.bool()] = 0\n",
    "    return ret\n",
    "\n",
    "\n",
    "if EXPERIMENT_TYPE == LIME:\n",
    "    attributers = {\n",
    "        char: attr.LimeBase(\n",
    "            softmax_results,\n",
    "            interpretable_model=SkLearnLasso(alpha=0.0005),\n",
    "            similarity_func=exp_embedding_cosine_distance,\n",
    "            perturb_func=bernoulli_perturb,\n",
    "            perturb_interpretable_space=True,\n",
    "            from_interp_rep_transform=interp_to_input,\n",
    "            to_interp_rep_transform=None,\n",
    "        )\n",
    "        for char in label_tokens.keys()\n",
    "    }\n",
    "elif EXPERIMENT_TYPE == SHAP:\n",
    "    attributers = {\n",
    "        char : attr.KernelShap(softmax_results)\n",
    "        for char in label_tokens.keys()\n",
    "    }\n",
    "else:\n",
    "    raise Exception(\"Invalid Experiment Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = {}\n",
    "for char, label_token in label_tokens.items():\n",
    "    attributions[char] = attributers[char].attribute(\n",
    "        tokens, target=label_token, n_samples=512, show_progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 85])\n"
     ]
    }
   ],
   "source": [
    "print(attributions[\"A\"].shape)\n",
    "assert attributions[\"A\"].nonzero().numel() != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85])\n",
      "['<s>', 'Please', 'select', 'the', 'option', 'that', 'most', 'closely', 'describes', 'the', 'following', 'claim', 'by', 'Jorge', 'El', 'or', 'za', ':', '\\n', 'The', 'reality', 'is', 'that', 'we', 'have', 'roughly', '', '1', '5', ',', '0', '0', '0', 'und', 'ocument', 'ed', 'immigrants', 'living', 'in', 'the', 'state', '...', '\\n', '\\n', 'A', ')', 'True', '\\n', 'B', ')', 'Most', 'ly', 'True', '\\n', 'C', ')', 'Half', 'True', '\\n', 'D', ')', 'B', 'arely', 'True', '\\n', 'E', ')', 'False', '\\n', 'F', ')', 'P', 'ants', 'on', 'Fire', '(', 'abs', 'urd', 'lie', ')', '\\n', '\\n', 'Choice', ':', '(']\n"
     ]
    }
   ],
   "source": [
    "all_tokens = tokens.squeeze(0)\n",
    "print(all_tokens.shape)\n",
    "all_tokens = list(map(tokenizer.decode, all_tokens))\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = softmax_results(tokens)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CustomDataRecord:\n",
    "    word_attributions: Any\n",
    "    pred_prob: torch.Tensor\n",
    "    pred_class: str\n",
    "    attr_class: str\n",
    "    attr_prob: torch.Tensor\n",
    "    attr_score: Any\n",
    "    raw_input_ids: Any | list[str]\n",
    "    convergence_delta: Any = None\n",
    "\n",
    "SCALE = 35\n",
    "\n",
    "attr_vis = [\n",
    "    CustomDataRecord(\n",
    "        attributions[char][0] * SCALE,  # word attributions\n",
    "        predictions[0].max(),  # predicted probability\n",
    "        tokenizer.decode(torch.argmax(predictions[0])),  # predicted class\n",
    "        char,  # attr class\n",
    "        predictions[0, label_tokens[char]],  # attr probability\n",
    "        attributions[char].sum(),  # attr score\n",
    "        all_tokens,  # raw input ids\n",
    "        abs(predictions[0, label_tokens[char]] - attributions[char].sum()) if EXPERIMENT_TYPE == SHAP else None\n",
    "    )\n",
    "    for char in attributions.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def visualize_text(\n",
    "    datarecords: list[CustomDataRecord], legend: bool = True\n",
    ") -> \"HTML\":  # In quotes because this type doesn't exist in standalone mode\n",
    "    dom = [\"<table width: 100%>\"]\n",
    "    if EXPERIMENT_TYPE == LIME:\n",
    "        rows = [\n",
    "            \"<tr><th>Predicted Label</th>\"\n",
    "            \"<th>Attribution Label</th>\"\n",
    "            \"<th>Word Importance</th>\"\n",
    "        ]\n",
    "    else:\n",
    "        rows = [\n",
    "            \"<tr><th>Predicted Label</th>\"\n",
    "            \"<th>Attribution Label</th>\"\n",
    "            \"<th>Convergence Delta</th>\"\n",
    "            \"<th>Word Importance</th>\"\n",
    "        ]\n",
    "    for datarecord in datarecords:\n",
    "        if EXPERIMENT_TYPE == LIME:\n",
    "            rows.append(\n",
    "                \"\".join(\n",
    "                    [\n",
    "                        \"<tr>\",\n",
    "                        viz.format_classname(\n",
    "                            \"{0} ({1:.2f})\".format(\n",
    "                                datarecord.pred_class, datarecord.pred_prob\n",
    "                            )\n",
    "                        ),\n",
    "                        viz.format_classname(\n",
    "                            \"{0} ({1:.2f})\".format(\n",
    "                                datarecord.attr_class, datarecord.attr_prob\n",
    "                            )\n",
    "                        ),\n",
    "                        viz.format_word_importances(\n",
    "                            datarecord.raw_input_ids, datarecord.word_attributions\n",
    "                        ),\n",
    "                        \"<tr>\",\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            rows.append(\n",
    "                \"\".join(\n",
    "                    [\n",
    "                        \"<tr>\",\n",
    "                        viz.format_classname(\n",
    "                            \"{0} ({1:.2f})\".format(\n",
    "                                datarecord.pred_class, datarecord.pred_prob\n",
    "                            )\n",
    "                        ),\n",
    "                        viz.format_classname(\n",
    "                            \"{0} ({1:.2f})\".format(\n",
    "                                datarecord.attr_class, datarecord.attr_prob\n",
    "                            )\n",
    "                        ),\n",
    "                        viz.format_classname(\"{0:.2f}\".format(datarecord.convergence_delta)),\n",
    "                        viz.format_word_importances(\n",
    "                            datarecord.raw_input_ids, datarecord.word_attributions\n",
    "                        ),\n",
    "                        \"<tr>\",\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "    if legend:\n",
    "        dom.append(\n",
    "            '<div style=\"border-top: 1px solid; margin-top: 5px; \\\n",
    "            padding-top: 5px; display: inline-block\">'\n",
    "        )\n",
    "        dom.append(\"<b>Legend: </b>\")\n",
    "\n",
    "        for value, label in zip([-1, 0, 1], [\"Negative\", \"Neutral\", \"Positive\"]):\n",
    "            dom.append(\n",
    "                '<span style=\"display: inline-block; width: 10px; height: 10px; \\\n",
    "                border: 1px solid; background-color: \\\n",
    "                {value}\"></span> {label}  '.format(\n",
    "                    value=viz._get_color(value), label=label\n",
    "                )\n",
    "            )\n",
    "        dom.append(\"</div>\")\n",
    "\n",
    "    dom.append(\"\".join(rows))\n",
    "    dom.append(\"</table>\")\n",
    "    html = HTML(\"\".join(dom))\n",
    "    display(html)\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_MAP[full_liar[k]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>Predicted Label</th><th>Attribution Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>A (0.53)</b></text></td><td><text style=\"padding-right:2em\"><b>A (0.53)</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Please                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> select                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> option                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> most                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> closely                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> describes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> following                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> claim                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Jorge                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> El                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> za                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reality                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(0, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roughly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 5                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 0                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 0                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 0                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> und                    </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ocument                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ed                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> immigrants                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> living                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> state                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ...                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> A                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> True                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> B                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Most                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ly                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> True                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(120, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> C                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Half                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> True                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> D                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> B                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> arely                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> True                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> E                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> False                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> F                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> P                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ants                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Fire                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> abs                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> urd                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> lie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> \n",
       "                    </font></mark><mark style=\"background-color: hsl(0, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Choice                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n"
     ]
    }
   ],
   "source": [
    "html = visualize_text(attr_vis)\n",
    "print(\"Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14392"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(f\"{model_name[model_name.index('/')+1:]}_{EXPERIMENT_TYPE.lower()}_side.html\", \"w\").write(html.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# save pts as well\n",
    "torch.save(\n",
    "    OrderedDict(attributions),\n",
    "    f\"{model_name[model_name.index('/')+1:]}_{EXPERIMENT_TYPE.lower()}.pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
